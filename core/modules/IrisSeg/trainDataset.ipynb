{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN\n",
    "Implementation by Matterport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn import model_selection\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "# WxH for datasets.\n",
    "HEIGHT = 280\n",
    "WIDTH = 320\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to COCO trained weights\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "#Path to dataset, this folder holds train,test and valid datasets. Each folder has two folders (iris,mask)\n",
    "DATASET_PATH = \"/dividedDataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisConfig(Config):\n",
    "    \n",
    "    \n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"irises\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    #MINI_MASK_SHAPE = (84, 84)  \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 3 shapes\n",
    "    RPN_ANCHOR_STRIDE = 2\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 240\n",
    "    IMAGE_MAX_DIM = 640\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    #Ubiris only\n",
    "    MEAN_PIXEL = np.array([ 127.8, 90.1, 76.3])\n",
    "    #IMAGE_SHAPE  = [320,256,3]\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "    #MINI_MASK_SHAPE = [40,40]\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    #TRAIN_ROIS_PER_IMAGE = 48\n",
    "    \n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 500\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 20    \n",
    "    #Iris shape, Casia only for now\n",
    "config = irisConfig()\n",
    "config.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "## Must divide iris dataset statically\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import skimage\n",
    "from skimage import io\n",
    "from sklearn import model_selection\n",
    "from skimage import util\n",
    "from numpy import newaxis\n",
    "import cv2\n",
    "\n",
    "# Loading the dataset, static folder for now\n",
    "datasetLoc = ROOT_DIR + DATASET_PATH\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "    \n",
    "        \n",
    "class irisDataset(utils.Dataset):\n",
    "    dType = \"\"\n",
    "    y_valid = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    def getmaskLoc(self,y_trai,y_vali):\n",
    "        self.Y_training = y_trai\n",
    "        self.Y_valid = y_vali\n",
    "        print (str(len(dataset_train.Y_training)))\n",
    "\n",
    "\n",
    "    def loadIris(self,dataset):\n",
    "        print (self.dType)\n",
    "        os.chdir(ROOT_DIR)\n",
    "        cwd = os.getcwd()\n",
    "        print (cwd)\n",
    "        self.add_class(\"iris\",1,\"iris\")\n",
    "        if(dataset == \"train\"):\n",
    "            trainIris = datasetLoc + \"train/iris\"\n",
    "            os.chdir(trainIris)\n",
    "            X_train = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "\n",
    "            trainMask = datasetLoc +\"train/mask\"\n",
    "            os.chdir(trainMask)\n",
    "            self.y_train = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "            \n",
    "            \n",
    "            for i in range((len(X_train))-1):\n",
    "                self.add_image(\"iris\",image_id = i,path = datasetLoc + \"train/iris/\" + X_train[i],width = WIDTH,height = HEIGHT)\n",
    "        if(dataset == \"valid\"):\n",
    "\n",
    "            validIris = datasetLoc + \"valid/iris\"\n",
    "            os.chdir(validIris)\n",
    "            X_valid = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "\n",
    "            validMask = datasetLoc + \"valid/mask\"\n",
    "            os.chdir(validMask)\n",
    "            self.y_valid = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "            \n",
    "            for i in range((len(X_valid))-1):\n",
    "                self.add_image(\"iris\",image_id = i,path = datasetLoc + \"valid/iris/\" +  X_valid[i],width = WIDTH,height = HEIGHT)\n",
    "\n",
    "        if(dataset == \"test\"):\n",
    "            testIris = datasetLoc + \"test/iris\"\n",
    "            os.chdir(testIris)\n",
    "            X_test = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "\n",
    "            testMask = datasetLoc +\"test/mask\"\n",
    "            os.chdir(testMask)\n",
    "            self.y_test = sorted(glob.glob(\"*\"),key=numericalSort)  \n",
    "            \n",
    "            for i in range((len(X_test))-1):\n",
    "                self.add_image(\"iris\",image_id = i,path = datasetLoc + \"test/iris/\" + X_test[i],width = WIDTH,height = HEIGHT)\n",
    "\n",
    "        \n",
    "    def load_mask(self,image_id):\n",
    "        \n",
    "        cwd = os.getcwd()\n",
    "        image = np.ones(shape=(HEIGHT,WIDTH))\n",
    "        \n",
    "        if(self.dType == \"train\"):\n",
    "            #print (len(self.y_train))\n",
    "\n",
    "            image = skimage.io.imread(datasetLoc +\"train/mask/\" +self.y_train[image_id],as_grey=True)\n",
    "            image = skimage.color.rgb2gray(image)\n",
    "        if(self.dType == \"test\"):\n",
    "            #print (len(self.y_test))\n",
    "\n",
    "            image = skimage.io.imread(datasetLoc +\"test/mask/\" +self.y_test[image_id],as_grey=True)\n",
    "            image = skimage.color.rgb2gray(image)\n",
    "\n",
    "        if(self.dType == \"valid\"):\n",
    "            #print (len(self.y_valid))\n",
    "\n",
    "            image = skimage.io.imread(datasetLoc +\"valid/mask/\" +self.y_valid[image_id],as_grey=True)\n",
    "            image = skimage.color.rgb2gray(image)\n",
    "\n",
    "        class_ids = np.array([1])\n",
    "        #New axis due to 1+ number of mask classes in actual implementation\n",
    "        mask = image[:,:,newaxis]\n",
    "\n",
    "        for x in range (mask.shape[0]):\n",
    "            for y in range (mask.shape[1]):\n",
    "                if mask[x][y] == 1:\n",
    "                    mask[x][y][0] = 1\n",
    "        return mask,class_ids\n",
    "        \n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "# Training dataset\n",
    "dataset_train = irisDataset(\"train\")\n",
    "dataset_train.dType = \"train\"\n",
    "dataset_train.loadIris(\"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = irisDataset(\"valid\")\n",
    "dataset_val.dType = \"valid\"\n",
    "dataset_val.loadIris(\"valid\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Test Dataset\n",
    "dataset_test = irisDataset(\"test\")\n",
    "dataset_test.dType = \"test\"\n",
    "dataset_test.loadIris(\"test\")\n",
    "dataset_test.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(ROOT_DIR + \"/logs\")\n",
    "# Displays random samples from each partition of the dataset\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 2)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    print (image.shape)\n",
    "    print (image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print (mask.shape)    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "    \n",
    "image_ids = np.random.choice(dataset_val.image_ids, 2)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    print (image_id)\n",
    "    mask, class_ids = dataset_val.load_mask(image_id)\n",
    "    print (mask.shape)    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_val.class_names)\n",
    "    \n",
    "image_ids = np.random.choice(dataset_test.image_ids, 2)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    print (image_id)\n",
    "    mask, class_ids = dataset_test.load_mask(image_id)\n",
    "    print (mask.shape)    \n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    print (COCO_MODEL_PATH)\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last()[1], by_name=True)\n",
    "    print (model.find_last()[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Training only the head layers\n",
    "\n",
    "2. Fine tuning left over layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "              \n",
    "\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=8, \n",
    "            layers='all',\n",
    "            augmentation = augmentation\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=16, \n",
    "            layers='5+',\n",
    "            augmentation = augmentation\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=24, \n",
    "            layers='all',\n",
    "            augmentation = augmentation\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
